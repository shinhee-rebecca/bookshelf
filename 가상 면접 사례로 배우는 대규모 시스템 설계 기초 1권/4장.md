# 4장 처리율 제한 장치의 설계
## 처리율 제한 장치의 필요성
1. 다수의 사용자가 서비스를 쾌적하게 사용하도록 하기 위해
2. 서버의 과부하를 막기 위해
3. DoS, DDoS 공격을 방지하기 위해

## 처리율 제한 알고리즘
#### 토큰 버킷 알고리즘
- 일정 시간마다 버킷에 토큰이 채워지고 (최대 개수 제한 O) 각 요청이 처리될 때마다 하나의 토큰을 필요로 함
- 2개의 인자
	- 버킷 크기 : 버킷에 담을 수 있는 토큰의 최대 개수
	- 토큰 공급률 : 초당 몇 개의 토큰이 버킷에 공급되는가
- 버킷은 통상적으로 API 엔드포인트마다 둠 (서비스마다 둘 수도 있음)
- 메모리 사용량 측면에서 효율적이나 버킷 크기와 토큰 공급률을 적절하게 튜닝하는 것이 어려움
#### 누출 버킷 알고리즘
- 요청이 도착하면 버킷이 가득찼는지 확인하고 가득찼으면 요청을 버리고 그렇지 않다면 요청을 큐로 보냄, 큐에서는 일정한 시간마다 고정된 속도로 요청을 처리하도록 시스템에 요청함
- 2개의 인자
	- 버킷 크기 : 큐 사이즈
	- 처리율 : 지정된 시간마다 몇 개의 항목을 처리할지 지정하는 값
- 메모리 사용량 측면에서 효율적이나 버킷 크기나 처리율을 적절하게 튜닝하는 것이 어려움
- 단기간에 많은 트래픽이 몰리는 경우 큐에 도착한 최신 요청들은 버려질 수 있음
#### 고정 윈도 카운터 알고리즘
- 타임라인을 고정된 간격의 윈도로 나누고 각 윈도마다 카운터를 붙임. 이 카운터 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려짐.
- 장점 : 메모리 효율이 좋으며 특정한 트래픽 패턴을 처리하기에 적합함.
- 단점 : 윈도 경계 부근에 일시적으로 많은 트래픽이 몰리는 경우 기대했던 시스템의 처리 한도보다 많은 양을 처리하게 됨.
#### 이동 윈도 로깅 알고리즘
- 고정 윈도 카운터 알고리즘의 단점을 보완한 알고리즘으로 요청의 타임스탬프를 추적함. 요청 도착 -> 만료된 로그 삭제 -> 요청 처리 가능 여부 확인의 순서.
- 장점 : 어느 순간의 윈도를 보더라도 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않음
- 단점 : 사용자가 요청을 계속 보내서 운좋게 슬라이딩 윈도의 경계가 밀릴 때 요청이 허용되지 않도록 하기 위해서 거부된 요청의 타임스탬프도 보관해야 하므로 다량의 메모리를 필요로 함
#### 이동 윈도 카운터 알고리즘
- 고정 윈도 카운터 알고리즘 + 이동 윈도 로깅 알고리즘
- 현재 1분간의 요청 수 + (직전 1분간의 요청 수)*(이동 윈도와 직전 1분이 겹치는 비율)
- 장점 : 메모리 효율이 좋고 짧은 시간에 몰리는 트래픽에도 잘 대응함
- 단점 : 다소 느슨함

## 분산 환경
#### 경쟁 조건
lock을 사용하면 시스템의 성능이 떨어지므로 루아스크립트나 정렬 집합을 사용하는 것을 권장함
- 루아 스크립트 : 여러 레디스 명령을 하나의 스크립트로 묶어서 중간에 끼어들 틈 없이 실행함
#### 동기화 이슈
고정 세션을 사용하기보다는 레디스 등을 사용하는 것을 권장함

## 고려할 사항
#### 처리율 제한 장치의 위치
- 클라이언트 : 쉽게 위변조할 수 있기 때문에 신뢰할 수 없음
- 서버 : 소규모 트래픽일 경우 사용됨
- 미들웨어 : API 게이트웨이에 구현하는 것이 일반적임
#### 클라이언트 설계
- 캐시를 사용하여 API 호출 횟수를 줄임
- 재시도 로직을 구현할 때는 충분한 백오프 시간을 둠
#### 고려할 사항
- 처리율 제한은 IP 주소별 vs 사용자 ID별
- 처리율 제한은 API endpoint 별 vs 서버별
- 경성 처리율 제한 vs 연성 처리율 제한
- 다양한 계층에서의 처리율 제한
	- 위에서는 APP 계층에서의 처리율 제한만 다뤘으나 Network 계층에서의 처리율 제한도 가능함 (L4/L7 로드밸런서, 방화벽, 게이트웨이에서 처리)
